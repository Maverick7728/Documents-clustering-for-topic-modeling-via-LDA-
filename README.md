# Documents-clustering-for-topic-modeling-via-LDA-

## Introduction

The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned evenly across 20 newsgroups. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and clustering.

dataset link: https://archive.ics.uci.edu/dataset/113/twenty+newsgroups

# Document Clustering for Topic Modelling & Classification

## Project Overview
This project focuses on document clustering for topic modeling and classification using the 20 Newsgroups dataset. It demonstrates various natural language processing (NLP) techniques and machine-learning text analysis approaches.

## Features
- Data preprocessing and cleaning
- Tokenization and stop word removal
- Bigram and trigram model building
- Lemmatization
- Exploratory data analysis with word clouds and frequency distributions
- Vocabulary building and filtering

## Technologies Used
- Python
- NLTK
- Gensim
- spaCy
- Matplotlib
- WordCloud

## Key Components
1. Data Loading and Preprocessing
2. Tokenization and Cleaning
3. Bigram and Trigram Model Creation
4. Lemmatization
5. Exploratory Data Analysis
6. Vocabulary Building

## Installation
```bash
pip install nltk gensim spacy matplotlib wordcloud
python -m spacy download en_core_web_lg
